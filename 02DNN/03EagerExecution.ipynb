{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"03EagerExecution.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"SlQjg3jIJnl6","colab_type":"text"},"source":["# 텐서플로우 즉시 실행 (TensorFlow Eager Execution)\n","텐서플로우의 즉시 실행 (Eager execution)은 그래프 생성 없이 연산을 즉시 실행하는 명령형 프로그래밍 환경을 뜻한다. 각 연산들은 나중에 실행할 계산 그래프를 만드는 것이 아니라, 실제 값이 반환된다. 이를 통해 텐서플로우를 좀더 쉽게 시작할 수 있고, 모델을 디버그 할 수 있다. 또한 불필요한 구문도 줄여준다. \n","\n","* 직관적인 인터페이스—사용자 코드를 자연스럽게 구조화 하고, 파이썬 데이터 구조를 사용한다. 작은 모델과 작은 데이터에 대해서도 빠르게 반복수행 가능하다.\n","* 쉬운 디버깅—실행중인 모델을 검사하거나 변화사항을 평가할 때 연산들을 직접 호출할 수 있다.\n","* 자연스러운 흐름 제어—동적 모델의 명세를 단순화 시켜, 그래프 흐름 제어 대신 파이썬 흐름 제어를 사용할 수 있다.  \n","\n","즉시 실행 (eager execution)은 텐서플로우의 대부분 연산 및 GPU 가속화를 지원한다.  \n","\n","즉시 실행 (eager execution)을 시작하기 위해서, tf.enable_eager_execution() 구문을 프로그램이나 콘솔세션 제일 첫 부분에 추가한다."]},{"cell_type":"code","metadata":{"id":"sQ4TZJKvJnl8","colab_type":"code","outputId":"deb3dff1-3c0a-481b-9a0f-44ff97ce3ba4","executionInfo":{"status":"ok","timestamp":1573980399765,"user_tz":-540,"elapsed":2321,"user":{"displayName":"이선화","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAaVHDHE1MIY1LHmJ_yWOBQMBjk_0EAJ4f0eWo-=s64","userId":"17814374716323603424"}},"colab":{"base_uri":"https://localhost:8080/","height":81}},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["1.15.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EQjt8OekJnmA","colab_type":"text"},"source":["###  Without Eager Execution\n","```\n","tf.enable_eager_execution()\n","\n","tf.executing_eagerly()        # => True\n","\n","a = tf.constant([[1.,2.], [3.,4.]])\n","print(a)\n","print(tf.matmul(a,a))\n","```\n","수행 결과는 다음과 같다.\n","\n","```\n","Tensor(\"Const:0\", shape=(2, 2), dtype=float32)\n","Tensor(\"MatMul:0\", shape=(2, 2), dtype=float32)\n","```\n","Eager Execution을 쓰지 않을 경우에는 다음과 같이 session을 수행해야 원하는 결과를 확인할 수 있다.\n","\n","```\n","with tf.Session() as sess:\n","    print(sess.run(a))\n","    print(sess.run(tf.matmul(a,a)))\n","```\n","```\n","[[1. 2.]\n"," [3. 4.]]\n","[[ 7. 10.]\n"," [15. 22.]]\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"SWedjf2iJnmB","colab_type":"text"},"source":["### With Eager Execution \n","즉시 실행 (eager execution)을 활성화하여 텐서플로우 연산이 즉시 실행되어 파이썬에게 그 값을 반환하여 줄 수 있도록 동작을 바꾸게 된다."]},{"cell_type":"code","metadata":{"id":"xBF_RQOiJnmB","colab_type":"code","outputId":"b3ff3ab1-f7fc-4f97-a4d7-3465eb035815","executionInfo":{"status":"ok","timestamp":1573980399766,"user_tz":-540,"elapsed":2311,"user":{"displayName":"이선화","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAaVHDHE1MIY1LHmJ_yWOBQMBjk_0EAJ4f0eWo-=s64","userId":"17814374716323603424"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tf.enable_eager_execution()\n","\n","tf.executing_eagerly()        # => True"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"7HLQ2PmEJnmF","colab_type":"code","outputId":"12d75c97-b0ab-4241-a64b-e5ac7a197625","executionInfo":{"status":"ok","timestamp":1573980399767,"user_tz":-540,"elapsed":2304,"user":{"displayName":"이선화","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAaVHDHE1MIY1LHmJ_yWOBQMBjk_0EAJ4f0eWo-=s64","userId":"17814374716323603424"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["a = tf.constant([[1.,2.], [3.,4.]])\n","print(a)\n","print(tf.matmul(a,a))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["tf.Tensor(\n","[[1. 2.]\n"," [3. 4.]], shape=(2, 2), dtype=float32)\n","tf.Tensor(\n","[[ 7. 10.]\n"," [15. 22.]], shape=(2, 2), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2onTZFAkJnmH","colab_type":"text"},"source":["# Numpy 호환성\n","즉시 실행 (eager execution)은 NumPy와 호환성이 매우 뛰어나다. \n","* NumPy 연산은 tf.Tensor를 인자로 받는다. \n","* 텐서플로우 수학 연산은 파이썬 객체와 NumPy 배열을 tf.Tensor 객체로 변환한다. \n","* tf.Tensor.numpy 함수는 객체의 값을 NumPy ndarray형태로 반환합니다."]},{"cell_type":"code","metadata":{"id":"IN42xEe7JnmI","colab_type":"code","outputId":"9c487a86-d9ce-42bb-8c7f-f7c61195cb5f","executionInfo":{"status":"ok","timestamp":1573980399768,"user_tz":-540,"elapsed":2298,"user":{"displayName":"이선화","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAaVHDHE1MIY1LHmJ_yWOBQMBjk_0EAJ4f0eWo-=s64","userId":"17814374716323603424"}},"colab":{"base_uri":"https://localhost:8080/","height":245}},"source":["a = tf.constant([[1, 2],\n","                 [3, 4]])\n","print(a)\n","# => tf.Tensor([[1 2]\n","#               [3 4]], shape=(2, 2), dtype=int32)\n","\n","# 브로드캐스팅을 지원합니다.\n","b = tf.add(a, 1)\n","print(b)\n","# => tf.Tensor([[2 3]\n","#               [4 5]], shape=(2, 2), dtype=int32)\n","\n","# 연산자 오버로딩을 지원합니다.\n","print(a * b)\n","# => tf.Tensor([[ 2  6]\n","#               [12 20]], shape=(2, 2), dtype=int32)\n","\n","# NumPy 값을 써봅시다.\n","import numpy as np\n","\n","c = np.multiply(a, b)\n","print(c)\n","# => [[ 2  6]\n","#     [12 20]]\n","\n","# 텐서로부터 numpy 형태의 값 받기:\n","print(a.numpy())\n","# => [[1 2]\n","#     [3 4]]"],"execution_count":4,"outputs":[{"output_type":"stream","text":["tf.Tensor(\n","[[1 2]\n"," [3 4]], shape=(2, 2), dtype=int32)\n","tf.Tensor(\n","[[2 3]\n"," [4 5]], shape=(2, 2), dtype=int32)\n","tf.Tensor(\n","[[ 2  6]\n"," [12 20]], shape=(2, 2), dtype=int32)\n","[[ 2  6]\n"," [12 20]]\n","[[1 2]\n"," [3 4]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-4_4fUq-JnmL","colab_type":"text"},"source":["# 동적 흐름 제어 (Dynamic control flow)\n","\n","### Without Eager Execution\n","```\n","b = tf.constant([1.,2.,3.])\n","for i in b:\n","    print(i)\n","\n","---------------------------------------------------------------------------\n","TypeError                                 Traceback (most recent call last)\n","<ipython-input-16-f72bc6bf22c1> in <module>\n","      2 \n","      3 b = tf.constant([1.,2.,3.])\n","----> 4 for i in b:\n","      5     print(i)\n","```\n","\n","### With Eager Execution\n","파이썬처럼 자연스러운 동적 흐름 제어가 가능하다."]},{"cell_type":"code","metadata":{"id":"18lNor4CJnmM","colab_type":"code","outputId":"b6aa450c-e04a-431c-df22-bb8a4e2a00b3","executionInfo":{"status":"ok","timestamp":1573980400081,"user_tz":-540,"elapsed":2604,"user":{"displayName":"이선화","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAaVHDHE1MIY1LHmJ_yWOBQMBjk_0EAJ4f0eWo-=s64","userId":"17814374716323603424"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["b = tf.constant([1.,2.,3.])\n","for i in b:\n","    print(i)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["tf.Tensor(1.0, shape=(), dtype=float32)\n","tf.Tensor(2.0, shape=(), dtype=float32)\n","tf.Tensor(3.0, shape=(), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EQws9bBWJnmQ","colab_type":"text"},"source":["# 즉시 학습 (Eager training)\n","\n","### 그래디언트 계산하기 - 자동미분\n","즉시 실행 (eager execution)이 수행되는 동안, tf.GradientTape를 이용하여 나중에 gradient 계산을 수행할 연산을 추적할 수 있다.\n","\n","정방향(forward-pass) 연산은 \"tape\"에 기록됩니다. 그다음 tape를 거꾸로 돌려 그래디언트를 계산한 후 tape를 폐기한다."]},{"cell_type":"code","metadata":{"id":"Wrb9s4bXJnmR","colab_type":"code","outputId":"45950b81-4668-4250-c01b-d5497f13a636","executionInfo":{"status":"ok","timestamp":1573980400082,"user_tz":-540,"elapsed":2598,"user":{"displayName":"이선화","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAaVHDHE1MIY1LHmJ_yWOBQMBjk_0EAJ4f0eWo-=s64","userId":"17814374716323603424"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["w = tf.Variable([[1.0]])\n","with tf.GradientTape() as tape:\n","  loss = w * w\n","\n","grad = tape.gradient(loss, w)\n","print(grad)  # => tf.Tensor([[ 2.]], shape=(1, 1), dtype=float32)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["tf.Tensor([[2.]], shape=(1, 1), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_emc5onQJnmV","colab_type":"text"},"source":["tf.Variable 객체는 자동 미분을 쉽게 하기 위해서 학습동안 변경된 tf.Tensor 값을 저장한다.  \n","\n","tf.Variable을 tf.GradientTape과 함께 사용하여 모델을 생성한다."]},{"cell_type":"code","metadata":{"id":"rbe7tTQkJnmW","colab_type":"code","outputId":"5a8589e1-89a5-48b0-9610-9a893025c46e","executionInfo":{"status":"ok","timestamp":1573980400738,"user_tz":-540,"elapsed":3247,"user":{"displayName":"이선화","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAaVHDHE1MIY1LHmJ_yWOBQMBjk_0EAJ4f0eWo-=s64","userId":"17814374716323603424"}},"colab":{"base_uri":"https://localhost:8080/","height":175}},"source":["class Model(tf.keras.Model):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        self.W = tf.Variable(5., name='weight')\n","        self.B = tf.Variable(10., name='bias')\n","    def call(self, inputs):\n","        return inputs * self.W + self.B\n","\n","# 약 3 * x + 2개의 점으로 구성된 실험 데이터\n","NUM_EXAMPLES = 2000\n","training_inputs = tf.random.normal([NUM_EXAMPLES])\n","noise = tf.random.normal([NUM_EXAMPLES])\n","training_outputs = training_inputs * 3 + 2 + noise\n","\n","# 최적화할 손실함수\n","def loss(model, inputs, targets):\n","    error = model(inputs) - targets\n","    return tf.reduce_mean(tf.square(error))\n","\n","def grad(model, inputs, targets):\n","    with tf.GradientTape() as tape:\n","        loss_value = loss(model, inputs, targets)\n","    return tape.gradient(loss_value, [model.W, model.B])\n","\n","# 정의:\n","# 1. 모델\n","# 2. 모델 파라미터에 대한 손실 함수의 미분\n","# 3. 미분에 기초한 변수 업데이트 전략\n","model = Model()\n","#optimizer = tf.keras.optimizers.SGD(lr=0.01)\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n","\n","print(\"초기 손실: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n","\n","# 반복 훈련\n","for i in range(300):\n","    grads = grad(model, training_inputs, training_outputs)\n","    optimizer.apply_gradients(zip(grads, [model.W, model.B]))\n","    if i % 50 == 0:\n","        print(\"스텝 {:03d}에서 손실: {:.3f}\".format(i, loss(model, training_inputs, training_outputs)))\n","\n","print(\"최종 손실: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n","print(\"W = {}, B = {}\".format(model.W.numpy(), model.B.numpy()))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["초기 손실: 68.937\n","스텝 000에서 손실: 66.256\n","스텝 050에서 손실: 9.704\n","스텝 100에서 손실: 2.147\n","스텝 150에서 손실: 1.137\n","스텝 200에서 손실: 1.002\n","스텝 250에서 손실: 0.984\n","최종 손실: 0.981\n","W = 2.9780404567718506, B = 2.0127627849578857\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HU1f0noWJnma","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}