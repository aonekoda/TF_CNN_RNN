{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JsEDR5QCl0Et","colab_type":"text"},"source":["# LSTM 실습\n","LSTM(Long Short Term Memory)는 좀 더 긴 타임 스텝의 데이터를 처리하기 위해 고안되었다. gradient vanishing 문제를 극복하여 성공적으로 모델링 할 수 있다. \n","\n","앞 선 실습에서 SimpleRNN 클래스를 LSTM 클래스로 바꾸기만 하면 LSTM 순환 신경망을 만들 수 있다."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"j6i2jodhCtp-","colab":{}},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oRWPdkUIhN26","colab_type":"text"},"source":["# 훈련데이터 준비\n","\n","* IMDB 데이터 사용 - Word Embedding은 단어 벡터의 크기를 임의로 조정하므로 사용되는 단어의 갯수에 크게 영향을 받지 않는다.\n","\n","* 이 경우 사용되는 단어의 갯수를 1000으로 한다."]},{"cell_type":"code","metadata":{"id":"AagDOCDfcqOq","colab_type":"code","colab":{}},"source":["import numpy as np\n","from tensorflow.keras.datasets import imdb"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ZDfoEg_ZE_0","colab_type":"code","colab":{}},"source":["(x_train_all, y_train_all), (x_test, y_test) = imdb.load_data(skip_top=20, num_words=1000)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Xn2krTqY34v","colab_type":"code","colab":{}},"source":["from tensorflow.keras.layers import Embedding"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lpORaDiIc8hn","colab_type":"code","colab":{}},"source":["for i in range(len(x_train_all)):\n","  x_train_all[i] = [w for w in x_train_all[i] if w > 2]\n","\n","print(x_train_all[0])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dnM909TXdVXl","colab_type":"code","colab":{}},"source":["\n","from sklearn.model_selection import train_test_split\n","\n","x_train,x_val,y_train,y_val = train_test_split(x_train_all, y_train_all, test_size=0.2, random_state=123)\n","\n","print(x_train.shape, x_val.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JxBu41lOdWSw","colab_type":"code","colab":{}},"source":["from tensorflow.keras.preprocessing import sequence\n","\n","max_len = 100\n","x_train_seq = sequence.pad_sequences(x_train, maxlen=max_len)\n","x_val_seq = sequence.pad_sequences(x_val, maxlen=max_len)\n","\n","print(x_train_seq.shape, x_val_seq.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d3SWcxgHePO6","colab_type":"text"},"source":["# 모형의 생성\n"]},{"cell_type":"code","metadata":{"id":"IEBhruXKeTM8","colab_type":"code","colab":{}},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UyMpeun8dq97","colab_type":"code","colab":{}},"source":["model_lstm = Sequential()\n","\n","####################\n","# TODO : 앞 선 실습에서 사용된 코드에서 SimpleRNN을 LSTM으로 변경하여 LSTM 모형을 생성하는\n","# 코드를 작성하여 보시오,\n","####################"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J-3SFtHYXxoR","colab_type":"text"},"source":["# 모델 컴파일 & 훈련 "]},{"cell_type":"code","metadata":{"id":"W6ezESOBX9eD","colab_type":"code","colab":{}},"source":["model_lstmcompile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","history=model_lstm.fit(x_train_seq, y_train, epochs=10, batch_size=32, \n","                      validation_data=(x_val_seq, y_val))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2PLTL3jMYoau","colab_type":"text"},"source":["# 모형 훈련 결과 시각화하기 "]},{"cell_type":"code","metadata":{"id":"lHDstQ1jZdDW","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","plt.plot(history.history['loss'], label='Train Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QgbQO65BZbMP","colab_type":"code","colab":{}},"source":["plt.plot(history.history['accuracy'], label='Train Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zhQHsThsYj9L","colab_type":"text"},"source":["# 모형의 평가\n","\n","모형의 정확도 점수를 출력해 보면 SimpleRNN보다 성능이 향상 된 것을 확인할 수 있다."]},{"cell_type":"code","metadata":{"id":"GmQyZK_rYhnH","colab_type":"code","colab":{}},"source":["loss, acc = model_lstm.evaluate(x_val_seq, y_val)\n","print(acc)"],"execution_count":0,"outputs":[]}]}